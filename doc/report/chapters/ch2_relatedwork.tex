%===================================== CHAP 2 =================================

\chapter{Reproducible Research}

\section{Terminology}

\section{Reproducible research}
Reproducible research was coined as a term in \cite{Claerbout1992} as the ability to recreate published figures and results from their data, parameters and programs. Claerbout and his colleagues began publishing CD-ROMs containing the text of their books as interactive documents where figures could be rebuilt from its original data and code. With the growth of the Internet and the world-wide-web, \cite{Buckheit1995} began distributing a software package called WaveLab\footnote{\url{https://statweb.stanford.edu/~wavelab/}} as freeware. WaveLab contained the software environment necessary to reproduce figures and results from their papers, developed in part due to Jon Claerbout's recommendations for really reproducible computational research. \cite{Buckheit1995} emphasized the idea that code and data for the process behind a presentation of results is required with a slogan condensing Claerbout's ideas: \begin{quote}\emph{"An article about computational science in a scientific publication is \emph{not} the scholarship itself, it is merely \emph{advertising} of the scholarship. The actual scholarship is the complete set of instructions which generated the figures."}\end{quote}

\cite{Peng2006} propose reproducible research as a minimum standard in epidemiologic research, stating that full replication is not always feasible. They define replication as \emph{"multiple independent investigators using independent data, analytical methods, laboratories, and instruments."} Criteria for research to be reproducible is defined as making analytical data, code underlying any principal results and the software environment available, and accompanied by adequate documentation to enable repeating the original and similar analyses. This is an important distinction, as reproducible research by this definition allows \emph{"1) verifying published findings, 2) conducting alternative analyses of the same data, 3) eliminating uninformed criticisms that do not stand up to existing data, and 4) expediting the interchange of ideas among investigators."} \citep{Peng2006} It does not, however, address issues prior to data analysis such as study design and data generation. As discussed in \cite{Vandewalle2007}, open access benchmark problems and data sets fit well in with the ideas and concepts of reproducible research. Notably, benchmarks for competitions do no allow the designers to choose the test set in a biased way, potentially addressing some of the issues not covered by reproducible research.

Stodden V. C. 2010 Reproducible research: Addressing the need for data and code sharing in computational science yale law school roundtable on data and code sharing.
Drummond 2012 Reproducible Research: a Dissenting Opinion

(Dror G. Feitelson. 2015. From Repeatability to Reproducibility and Corroboration. SIGOPS Oper. Syst. Rev. 49, 1 (January 2015), 3-11. DOI: http://dx.doi.org/10.1145/2723872.2723875 )




\section{Empirical Studies into Reproducibility}
Collberg et. al. (2014) Repeatability and Benefaction in Computer Systems Research
http://reproducibility.cs.arizona.edu/

J. Kovacevic, "How to Encourage and Publish Reproducible Research," 2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07, Honolulu, HI, 2007, pp. IV-1273-IV-1276. https://doi.org/10.1109/ICASSP.2007.367309
- "Reproducible research (RR) refers to the idea that in “computational” sciences, the ultimate product is not a published paper but rather the entire environment used to produce the results in the paper (data, software, etc.)."

P. Vandewalle, J. Kovacevic and M. Vetterli, "Reproducible research in signal processing," in IEEE Signal Processing Magazine, vol. 26, no. 3, pp. 37-47, May 2009. https://doi.org/10.1109/MSP.2009.932122
Strict requirements, and degrees of reproducibility.


\cite{Collberg2016} unable to even get code from authors for 44\% out of 402 papers from ACM conferences and journals.

Victoria C. Stodden, 2010, The Scientific Method in Practice: Reproducibility in the Computational Sciences, Columbia University Academic Commons, http://hdl.handle.net/10022/AC:P:11417.


\section{Observations}
Reproducible research provides readers the ability to verify findings presented in a publication rather than blindly trusting the results shown. Additionally, the more detailed documentation of the research allows thorough comparisons to corroborating research and attempts to independently implement experiments and methods. Thereby facilitating further research through more robust research and further corroboration of findings. Our approach to reproducible research focus on openness and transparency in methods and experiments, to allow review and discussion of research.
